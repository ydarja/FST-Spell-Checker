#!/usr/bin/env python3
""" Data Structures and Algorithms for CL III, Project 1
    See <https://dsacl3-2019.github.io/p1/> for detailed instructions.
    Authors:      Giulio Cusenza, Darja Jepifanova
    Honor Code:  We pledge that this program represents our own work.
    We received help from nobody
"""
import json

from fsa import FSA, build_trie
from fst import FST
import numpy as np


def build_editfst(alphabet, counts):
    """
    Build a weighted FST instance that implements one-edit-distance operations.

    You should use the add_transition() method of the FST class
    to build an FST that returns all misspellings of a word
    with one-edit-distance away.

    The transition weight should be set based on the number of times
    particular edit operations were observed in the data (e.g.,
    spelling-data.txt). You are recommended to estimate (smoothed)
    probabilities for each edit operation, and use its logarithm.
    You are free to experiment with weighting schemes, but remember
    that the transduce() method of FST assumes additive weights.

    Arguments:
    ----
    alphabet    All letters that we should recognize
    counts      Counts generated by compute-weights.py
    """
    edit_fst = FST()
    edit_fst.start_state = 0
    edit_fst.accepting = {1}

    # Add self-transitions
    for letter in alphabet:
        edit_fst.add_transition(0, letter, 0)
        edit_fst.add_transition(1, letter, 1)

    # Add transitions from 0 to 1 (i.e. one edit)
    alphabet.add("")
    for l1 in alphabet:
        for l2 in alphabet:
            if l1 != l2:
                weight = np.log10((counts[l1][l2] + 1) / (sum(counts[l1].values()) + len(counts[l1])))
                edit_fst.add_transition(0, l1, 1, l2, weight)

    return edit_fst


if __name__ == "__main__":

    # Example usage
    with open('lexicon.txt', 'rt') as f:
        words = f.read().strip().split()
    with open('spell-errors.json', 'rt') as f:
        errcount = json.loads(f.read())

    # Build the trie lexicon
    fsa = build_trie(words)
    # Minimize it
    fsa.minimize()
    # Convert it to an FST
    lexicon = FST.fromfsa(fsa)
    letters = set([char for word in words for char in word])
    # Build the edit-distance FST
    edits = build_editfst(letters, errcount)
    # Compose them
    spellfst = FST.compose_fst(lexicon, edits)
    # The above generates all spelling mistakes, we want the invert
    spellfst.invert()

    word = input("\nInsert word: ")
    print("Correction candidates for misspelt word \"" + word + "\"\n")
    for i, (sperr, w) in enumerate(sorted(spellfst.transduce(word), key=lambda x: x[1], reverse=True), start=1):
        print("\t"+str(i)+".", sperr, 10 ** w)
